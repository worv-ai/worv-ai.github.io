<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="Desktop gaming data effectively pretrains embodied AI: 152× compression via OWA Toolkit, YouTube pseudo-labeling with Generalist-IDM, achieving 96.6% on LIBERO manipulation and 83.3% on CANVAS navigation with 1.3K hours of data.">
    <meta name="keywords" content="Embodied Ai, Vision-Language-Action Models, Inverse Dynamics Models">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied AI</title>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-5J9LZW868J"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-5J9LZW868J');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="../static/css/bulma.min.css">
    <link rel="stylesheet" href="../static/css/slick.css">
    <link rel="stylesheet" href="../static/css/slick-theme.css">
    <link rel="stylesheet" href="../static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="../static/css/index.css">
    <link rel="icon" href="./static/images/favicon.ico">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="../static/js/fontawesome.all.min.js"></script>
    <script src="../static/js/slick.min.js"></script>
    <script src="../static/js/index.js"></script>
</head>

<body>

    <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
            <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu">
            <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
                <a class="navbar-item" href="../">
                    <span class="icon">
                        <i class="fas fa-home"></i>
                    </span>
                </a>

                <div class="navbar-item has-dropdown is-hoverable">
                    <a class="navbar-link">
                        More Research
                    </a>
                    <div class="navbar-dropdown">
                        <a class="navbar-item" href="../canvas/">
                            CANVAS: Commonsense-Aware Navigation System for Intuitive Human-Robot Interaction
                        </a>
                        <a class="navbar-item" href="../d2e/">
                            D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied AI
                        </a>
                        <a class="navbar-item" href="../costnav/">
                            CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents
                        </a>
                    </div>
                </div>
            </div>
        </div>

        </div>
    </nav>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-2 publication-title">D2E: Scaling Vision-Action Pretraining on Desktop Data
                            for Transfer to Embodied AI</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://suhwanchoi.me/">Suhwan Choi</a><sup>†1</sup>,</span>
                            </span>
                            <span class="author-block">
                                <a href="https://lastdefiance20.github.io/">Jaeyoon Jung</a><sup>†1</sup>,</span>
                            </span>
                            <span class="author-block">
                                <a href="https://hbseong97.github.io/">Haebin Seong</a><sup>†1</sup>,</span>
                            </span>
                            <span class="author-block">
                                <a href="https://minchankim.me/">Minchan Kim</a><sup>1</sup>,</span>
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=Jh3S9aAAAAAJ">Minyeong Kim</a><sup>2</sup>,</span>
                            </span>
                            <br>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=VxekekYAAAAJ">Yongjun Cho</a><sup>1</sup>,</span>
                            </span>
                            <span class="author-block">
                                Yoonshik Kim<sup>1</sup>,</span>
                            </span>
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/yu-been-park-7223a6234/">Yubeen Park</a><sup>1</sup>,</span>
                            </span>
                            <span class="author-block">
                                <a href="https://yj-yu.github.io/home/">Youngjae Yu</a><sup>‡3</sup>,</span>
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=7iaKhrEAAAAJ">Yunsung Lee</a><sup>‡1</sup>,</span>
                            </span>
                        </div>

                        <div class="is-size-6 publication-authors">
                            <span class="author-block">
                                <sup>†</sup> Equal contribution, <sup>‡</sup> Co-corresponding author, <sup>1</sup>
                                MAUM.AI, <sup>2</sup> Stanford University, <sup>3</sup> Seoul National University
                        </div>
                        <br>

                        <div class="is-size-5 publication-venue">
                            <span class="venue-block">International Conference on Learning Representations (ICLR)
                                2026</span>
                            <br>
                        </div>
                        <br>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2510.05684"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>

                                <!-- Video Link. -->
                                <!-- <span class="link-block">
                                    <a href="https://youtu.be/oJuU4x02azI"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-youtube"></i>
                                        </span>
                                        <span>Video</span>
                                    </a>
                                </span> -->
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="https://github.com/worv-ai/D2E"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github-alt"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <!-- Model Link. -->
                                <span class="link-block">
                                    <a href="https://huggingface.co/open-world-agents/Generalist-IDM-1B"
                                        class="external-link button is-normal is-rounded is-dark is-disabled">
                                        <span class="icon">
                                            <i class="fas fa-robot"></i>
                                        </span>
                                        <span>Model (G-IDM)</span>
                                    </a>
                                </span>
                                <!-- Dataset Link. -->
                                <span class="link-block">
                                    <a href="https://huggingface.co/datasets/open-world-agents/D2E-480p"
                                        class="external-link button is-normal is-rounded is-dark is-disabled">
                                        <span class="icon">
                                            <i class="fas fa-database"></i>
                                        </span>
                                        <span>Dataset (480p)</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://huggingface.co/datasets/open-world-agents/D2E-Original"
                                        class="external-link button is-normal is-rounded is-dark is-disabled">
                                        <span class="icon">
                                            <i class="fas fa-database"></i>
                                        </span>
                                        <span>Dataset (FHD/QHD)</span>
                                    </a>
                                </span>
                                <!-- Demo Link. -->
                                <!-- <span class="link-block">
                                    <a href="https://huggingface.co/spaces/maum-ai/CANVAS-DEMO"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-images"></i> </span>
                                        <span>Demo</span>
                                    </a>
                                </span> -->
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop is-centered has-text-justified is-size-5">
            <div class="hero-body">
                <figure id="teaser">
                    <img src="./static/images/1_teaser.png" alt="d2e teaser" />
                </figure>
                <p>
                    Overview of D2E (Desktop to Embodied AI) framework. (1) The OWA Toolkit captures 335.6 hours of rich
                    desktop demonstrations across 31 games with 152× compression. (2) The Generalist-IDM uses nextevent
                    prediction with temporal offset (NEP-τ) to achieve OOD generalization, enabling pseudolabeling of
                    1K+ hours of YouTube gameplay. (3) Vision-Action Pretraining transfers desktoppretrained
                    representations to embodied AI, achieving 96.6% success on LIBERO manipulation and
                    83.3% on CANVAS navigation benchmarks which demonstrates desktop-to-robotics transfer.
                </p>
            </div>
        </div>
    </section>

    <!-- Results Carousel -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <h1 class="title has-text-centered">Pseudo-Label result on YouTube dataset</h1>
                <div class="columns is-multiline">
                    <div class="column is-3">
                        <video poster="" id="brotato" autoplay controls muted loop playsinline width="100%">
                            <source src="./static/videos/youtube_brotato.mp4" type="video/mp4">
                        </video>
                        <p class="is-size-6 mt-2 has-text-centered">Brotato</p>
                    </div>
                    <div class="column is-3">
                        <video poster="" id="csgo2" autoplay controls muted loop playsinline width="100%">
                            <source src="./static/videos/youtube_csgo2.mp4" type="video/mp4">
                        </video>
                        <p class="is-size-6 mt-2 has-text-centered">CSGO2</p>
                    </div>
                    <div class="column is-3">
                        <video poster="" id="stardew" autoplay controls muted loop playsinline width="100%">
                            <source src="./static/videos/youtube_stardew.mp4" type="video/mp4">
                        </video>
                        <p class="is-size-6 mt-2 has-text-centered">Stardew Valley</p>
                    </div>
                    <div class="column is-3">
                        <video poster="" id="minecraft" autoplay controls muted loop playsinline width="100%">
                            <source src="./static/videos/youtube_minecraft.mp4" type="video/mp4">
                        </video>
                        <p class="is-size-6 mt-2 has-text-centered">Minecraft</p>
                    </div>
                    <div class="column is-3">
                        <video poster="" id="slime" autoplay controls muted loop playsinline width="100%">
                            <source src="./static/videos/youtube_slime.mp4" type="video/mp4">
                        </video>
                        <p class="is-size-6 mt-2 has-text-centered">Slime Rancher</p>
                    </div>
                    <div class="column is-3">
                        <video poster="" id="raft" autoplay controls muted loop playsinline width="100%">
                            <source src="./static/videos/youtube_raft.mp4" type="video/mp4">
                        </video>
                        <p class="is-size-6 mt-2 has-text-centered">Raft</p>
                    </div>
                    <div class="column is-3">
                        <video poster="" id="barony" autoplay controls muted loop playsinline width="100%">
                            <source src="./static/videos/youtube_barony.mp4" type="video/mp4">
                        </video>
                        <p class="is-size-6 mt-2 has-text-centered">Barony</p>
                    </div>
                    <div class="column is-3">
                        <video poster="" id="dinkum" autoplay controls muted loop playsinline width="100%">
                            <source src="./static/videos/youtube_dinkum.mp4" type="video/mp4">
                        </video>
                        <p class="is-size-6 mt-2 has-text-centered">Dinkum</p>
                    </div>
                </div>
                <div class="content has-text-centered mt-4">
                    <p class="is-size-6">
                        Generalist-IDM uses a single model to label actions on video-only
                        data, across 2D/3D games and visual navigation/UI interactions without separate processing. <br>
                        Remarkably, in Counter-Strike videos where spectator mode begins around 10 seconds,
                        it can distinguish between active gameplay and spectator mode by recognizing subtle UI elements,
                        avoiding action predictions during spectator phases.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Large language models leverage internet-scale text data, yet embodied AI remains constrained
                            by the prohibitive costs of physical trajectory collection. Desktop
                            environments---particularly gaming---offer a compelling alternative: they provide rich
                            sensorimotor interactions at scale while maintaining the structured observation-action
                            coupling essential for embodied learning. We present D2E (Desktop to Embodied AI), a
                            framework that demonstrates desktop interactions can serve as an effective pretraining
                            substrate for robotics embodied AI tasks. Unlike prior work that remained domain-specific
                            (e.g., VPT for Minecraft) or kept data proprietary (e.g., SIMA), D2E establishes a complete
                            pipeline from scalable desktop data collection to verified transfer in embodied domains. Our
                            framework comprises three components: (1) the OWA Toolkit that unifies diverse desktop
                            interactions into a standardized format with 152× compression, (2) the Generalist-IDM that
                            achieves strong zero-shot generalization across unseen games through timestamp-based event
                            prediction, enabling internet-scale pseudo-labeling, and (3) VAPT that transfers
                            desktop-pretrained representations to physical manipulation and navigation. Using 1.3K+
                            hours of data (259 hours of human demonstrations, and 1K+ hours of pseudo-labeled gameplay),
                            we achieve a total of 96.6% success rate on LIBERO manipulation and 83.3% on CANVAS
                            navigation benchmarks. This validates that sensorimotor primitives in digital interactions
                            exhibit sufficient invariance to transfer meaningfully to physical embodied tasks,
                            establishing desktop pretraining as a practical paradigm for robotics. We will make all our
                            work public, including the OWA toolkit, datasets of human-collected and pseudo-labeled, and
                            VAPT-trained models.
                        </p>
                    </div>
                </div>
            </div>

            <!--/ Abstract. -->
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Generalist Inverse Dynamics Model (G-IDM)</h2>
                    <div class="content has-text-justified">
                        <figure id="gidm_id">
                            <img src="./static/images/3-gidm-id.png" alt="gidm_id" />
                        </figure>
                        <p>
                            The Generalist Inverse Dynamics Model (G-IDM) learns to predict actions from observation
                            transitions across diverse desktop environments.
                            This enables zero-shot generalization to unseen games and provides a foundation for
                            pseudo-labeling large-scale gameplay data.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- G-IDM Video Examples -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div class="field">
                    <div class="control">
                        <div class="select is-fullwidth">
                            <select id="gidm-game-selector">
                                <option value="game2">Brotato (2D)</option>
                                <option value="game1">Minecraft (3D)</option>
                            </select>
                        </div>
                    </div>
                </div>

                <div id="game1" class="game-videos" style="display: none;">
                    <div class="columns is-multiline">
                        <div class="column is-4">
                            <video poster="" id="minecraft-gt" controls muted loop playsinline width="100%">
                                <source src="./static/videos/minecraft-gt.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">Ground Truth</p>
                        </div>
                        <div class="column is-4">
                            <video poster="" id="minecraft-idm" controls muted loop playsinline width="100%">
                                <source src="./static/videos/minecraft-idm.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">IDM</p>
                        </div>
                        <div class="column is-4">
                            <video poster="" id="minecraft-gidm" controls muted loop playsinline width="100%">
                                <source src="./static/videos/minecraft-gidm.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">G-IDM</p>
                        </div>
                    </div>
                </div>

                <div id="game2" class="game-videos">
                    <div class="columns is-multiline">
                        <div class="column is-4">
                            <video poster="" id="brotato-gt" controls muted loop playsinline width="100%">
                                <source src="./static/videos/brotato-gt.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">Ground Truth</p>
                        </div>
                        <div class="column is-4">
                            <video poster="" id="brotato-idm" controls muted loop playsinline width="100%">
                                <source src="./static/videos/brotato-idm.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">IDM</p>
                        </div>
                        <div class="column is-4">
                            <video poster="" id="brotato-gidm" controls muted loop playsinline width="100%">
                                <source src="./static/videos/brotato-gidm.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">G-IDM</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Out-of-Distribution Generalization</h2>
                    <div class="content has-text-justified">
                        <figure id="gidm_ood">
                            <img src="./static/images/4-gidm-ood.png" alt="gidm_ood" />
                        </figure>
                        <p>
                            G-IDM demonstrates strong out-of-distribution generalization capabilities, successfully
                            transferring learned sensorimotor patterns
                            from desktop gaming environments to completely unseen game domains and interaction
                            modalities.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- OOD Results -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div class="field">
                    <div class="control">
                        <div class="select is-fullwidth">
                            <select id="ood-game-selector">
                                <option value="ood1">Battlefield 6 (3D)</option>
                                <option value="ood2">Ogu and the Secret Forest (2D)</option>
                            </select>
                        </div>
                    </div>
                </div>

                <div id="ood1" class="ood-videos">
                    <div class="columns is-multiline">
                        <div class="column is-one-fifth">
                            <video poster="" id="battlefield-gt" controls muted loop playsinline width="100%">
                                <source src="./static/videos/battlefield-gt.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">Ground Truth</p>
                        </div>
                        <div class="column is-one-fifth">
                            <video poster="" id="battlefield-idm-ft" controls muted loop playsinline width="100%">
                                <source src="./static/videos/battlefield-idm-ft.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">IDM (Fine Tune)</p>
                        </div>
                        <div class="column is-one-fifth">
                            <video poster="" id="battlefield-gidm-zero" controls muted loop playsinline width="100%">
                                <source src="./static/videos/battlefield-gidm-zero.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">G-IDM (Zero Shot)</p>
                        </div>
                        <div class="column is-one-fifth">
                            <video poster="" id="battlefield-gidm-few" controls muted loop playsinline width="100%">
                                <source src="./static/videos/battlefield-gidm-few.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">G-IDM (Few Shot)</p>
                        </div>
                        <div class="column is-one-fifth">
                            <video poster="" id="battlefield-gidm-ft" controls muted loop playsinline width="100%">
                                <source src="./static/videos/battlefield-gidm-ft.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">G-IDM (Fine Tune)</p>
                        </div>
                    </div>
                    <div class="content has-text-justified mt-4">
                        <p class="is-size-6">
                            In Battlefield 6, for G-IDM (Zero Shot) we can observe that scale of mouse movement is
                            different with GT,
                            but we can observe that scale of movement remain nearly same for G-IDM (Few Shot).
                            This improvement occurs because providing context examples helps the model calibrate the
                            appropriate movement scale.
                        </p>
                    </div>
                </div>

                <div id="ood2" class="ood-videos" style="display: none;">
                    <div class="columns is-multiline">
                        <div class="column is-one-fifth">
                            <video poster="" id="oguforest-gt" controls muted loop playsinline width="100%">
                                <source src="./static/videos/oguforest-gt.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">Ground Truth</p>
                        </div>
                        <div class="column is-one-fifth">
                            <video poster="" id="oguforest-idm-ft" controls muted loop playsinline width="100%">
                                <source src="./static/videos/oguforest-idm-ft.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">IDM (Fine Tune)</p>
                        </div>
                        <div class="column is-one-fifth">
                            <video poster="" id="oguforest-gidm-zero" controls muted loop playsinline width="100%">
                                <source src="./static/videos/oguforest-gidm-zero.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">G-IDM (Zero Shot)</p>
                        </div>
                        <div class="column is-one-fifth">
                            <video poster="" id="oguforest-gidm-few" controls muted loop playsinline width="100%">
                                <source src="./static/videos/oguforest-gidm-few.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">G-IDM (Few Shot)</p>
                        </div>
                        <div class="column is-one-fifth">
                            <video poster="" id="oguforest-gidm-ft" controls muted loop playsinline width="100%">
                                <source src="./static/videos/oguforest-gidm-ft.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">G-IDM (Fine Tune)</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Desktop-to-Embodied Transfer</h2>
                    <div class="content has-text-justified">
                        <p>
                            To validate the effectiveness of desktop pretraining for embodied AI, we evaluate our
                            approach on three challenging downstream tasks:
                            <strong>LIBERO manipulation</strong>, <strong>CANVAS navigation</strong>, and
                            <strong>SO101 real-world pick-and-place</strong>. These
                            benchmarks represent diverse embodied scenarios
                            requiring different sensorimotor skills - precise object manipulation, spatial navigation,
                            and real-world pick-and-place.
                            Our Vision-Action Pretraining (VAPT) framework transfers desktop-pretrained representations
                            to these physical domains,
                            demonstrating that sensorimotor patterns learned from gaming environments can generalize to
                            real-world robotic tasks.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">LIBERO Manipulation Results</h2>
                    <div class="content has-text-justified">
                        <figure id="libero_results">
                            <img src="./static/images/5-libero.png" alt="libero_results" />
                        </figure>
                        <p>
                            D2E achieves impressive results on LIBERO manipulation benchmarks, demonstrating that
                            desktop-pretrained models
                            can effectively transfer to physical robotic manipulation tasks with a
                            <strong>96.6%</strong> success rate.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- LIBERO Video Examples -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div class="field">
                    <div class="control">
                        <div class="select is-fullwidth">
                            <select id="libero-task-selector">
                                <option value="task1">TASK: Put both the alphabet soup and the cream cheese box in the
                                    basket</option>
                                <option value="task2">TASK: Put both the alphabet soup and the tomato sauce in the
                                    basket</option>
                                <option value="task3">TASK: Put both moka pots on the stove</option>
                            </select>
                        </div>
                    </div>
                </div>

                <div id="task1" class="task-videos">
                    <div class="columns is-multiline">
                        <div class="column is-4">
                            <video poster="" id="libero-1-base" controls muted loop playsinline width="100%">
                                <source src="./static/videos/libero-1-base.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">Baseline (42%)</p>
                        </div>
                        <div class="column is-4">
                            <video poster="" id="libero-1-ft" controls muted loop playsinline width="100%">
                                <source src="./static/videos/libero-1-ft.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">+ VAPT w/o pseudo (98%)</p>
                        </div>
                        <div class="column is-4">
                            <video poster="" id="libero-1-ptft" controls muted loop playsinline width="100%">
                                <source src="./static/videos/libero-1-ptft.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">+ VAPT w/ pseudo (100%)</p>
                        </div>
                    </div>
                </div>

                <div id="task2" class="task-videos" style="display: none;">
                    <div class="columns is-multiline">
                        <div class="column is-4">
                            <video poster="" id="libero-2-base" controls muted loop playsinline width="100%">
                                <source src="./static/videos/libero-2-base.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">Baseline (36%)</p>
                        </div>
                        <div class="column is-4">
                            <video poster="" id="libero-2-ft" controls muted loop playsinline width="100%">
                                <source src="./static/videos/libero-2-ft.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">+ VAPT w/o pseudo (88%)</p>
                        </div>
                        <div class="column is-4">
                            <video poster="" id="libero-2-ptft" controls muted loop playsinline width="100%">
                                <source src="./static/videos/libero-2-ptft.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">+ VAPT w/ pseudo (90%)</p>
                        </div>
                    </div>
                </div>

                <div id="task3" class="task-videos" style="display: none;">
                    <div class="columns is-multiline">
                        <div class="column is-4">
                            <video poster="" id="libero-3-base" controls muted loop playsinline width="100%">
                                <source src="./static/videos/libero-3-base.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">Baseline (10%)</p>
                        </div>
                        <div class="column is-4">
                            <video poster="" id="libero-3-ft" controls muted loop playsinline width="100%">
                                <source src="./static/videos/libero-3-ft.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">+ VAPT w/o pseudo (88%)</p>
                        </div>
                        <div class="column is-4">
                            <video poster="" id="libero-3-ptft" controls muted loop playsinline width="100%">
                                <source src="./static/videos/libero-3-ptft.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">+ VAPT w/ pseudo (46%)</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">CANVAS Navigation Results</h2>
                    <div class="content has-text-justified">
                        <figure id="canvas_results">
                            <img src="./static/images/6-canvas.png" alt="canvas_results" />
                        </figure>
                        <p>
                            The framework also excels in navigation tasks, achieving <strong>83.3%</strong> success rate
                            on CANVAS navigation benchmarks,
                            validating the transferability of desktop sensorimotor patterns to embodied navigation
                            scenarios.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- CANVAS Video Examples -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div class="field">
                    <div class="control">
                        <div class="select is-fullwidth">
                            <select id="canvas-env-selector">
                                <option value="env1">Environment: sim_gallery</option>
                                <option value="env2">Environment: sim_street_sidewalk</option>
                            </select>
                        </div>
                    </div>
                </div>

                <div id="env1" class="env-videos">
                    <div class="columns is-multiline">
                        <div class="column is-6">
                            <video poster="" id="canvas-1-base" controls muted loop playsinline width="100%">
                                <source src="./static/videos/3_baseline_fail.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">Baseline (fail)</p>
                        </div>
                        <div class="column is-6">
                            <video poster="" id="canvas-1-vapt" controls muted loop playsinline width="100%">
                                <source src="./static/videos/3_vapt_success.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">+ VAPT w/ pseudo (success)</p>
                        </div>
                    </div>
                </div>

                <div id="env2" class="env-videos" style="display: none;">
                    <div class="columns is-multiline">
                        <div class="column is-6">
                            <video poster="" id="canvas-2-base" controls muted loop playsinline width="100%">
                                <source src="./static/videos/1_baseline_fail.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">Baseline (fail)</p>
                        </div>
                        <div class="column is-6">
                            <video poster="" id="canvas-2-vapt" controls muted loop playsinline width="100%">
                                <source src="./static/videos/1_vapt_success.mp4" type="video/mp4">
                            </video>
                            <p class="is-size-6 mt-2 has-text-centered">+ VAPT w/ pseudo (success)</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">SO101 Real-World Pick-and-Place</h2>
                    <div class="content has-text-justified">
                        <p>
                            We further validate our approach with a real-world pick-and-place experiment using an
                            SO101 robot arm, following the evaluation protocol of SmolVLA (Shukor et al., 2025). The
                            task requires grasping a blue cube and placing it in a white box, with the cube placed at
                            five distinct initial positions. We collect 208 demonstration episodes and evaluate each
                            trained policy over 30 rollouts. The baseline InternVL3-1B achieves a 70% success rate,
                            while both VAPT variants reach 80%, confirming that VAPT transfers effectively to
                            real-world hardware.
                        </p>
                        <div class="table-container">
                            <table class="table is-bordered is-striped is-fullwidth is-size-6">
                                <thead>
                                    <tr>
                                        <th rowspan="2">Method</th>
                                        <th colspan="5">Meta-World Success Rate (%)</th>
                                        <th rowspan="2">SO101 Pick&amp;Place (%)</th>
                                    </tr>
                                    <tr>
                                        <th>Easy</th>
                                        <th>Medium</th>
                                        <th>Hard</th>
                                        <th>Very Hard</th>
                                        <th>Avg</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>Baseline (InternVL3-1B)</td>
                                        <td>55.4</td>
                                        <td>14.5</td>
                                        <td>1.7</td>
                                        <td>8.0</td>
                                        <td>19.9</td>
                                        <td>70.0</td>
                                    </tr>
                                    <tr>
                                        <td>+ VAPT (w/o pseudo)</td>
                                        <td>53.6</td>
                                        <td>18.2</td>
                                        <td>8.3</td>
                                        <td>20.0</td>
                                        <td>25.0</td>
                                        <td>80.0</td>
                                    </tr>
                                    <tr>
                                        <td>+ VAPT (w/ pseudo)</td>
                                        <td>52.1</td>
                                        <td>16.4</td>
                                        <td>6.7</td>
                                        <td>24.0</td>
                                        <td>24.8</td>
                                        <td>80.0</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                        <p class="is-size-6 has-text-centered">
                            Table 8: Success rates on the Meta-World benchmark (by difficulty) and real-world
                            SO101 pick-and-place success rates (%).
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div class="columns is-multiline">
                    <div class="column is-6">
                        <video poster="" id="so101-baseline-right" controls muted loop playsinline width="100%">
                            <source src="./static/videos/so101_baseline_fail_right.mp4" type="video/mp4">
                        </video>
                        <p class="is-size-6 mt-2 has-text-centered">Baseline (fail) - right view</p>
                    </div>
                    <div class="column is-6">
                        <video poster="" id="so101-vapt-right" controls muted loop playsinline width="100%">
                            <source src="./static/videos/so101_ours_success_right.mp4" type="video/mp4">
                        </video>
                        <p class="is-size-6 mt-2 has-text-centered">+ VAPT (success) - right view</p>
                    </div>
                    <div class="column is-6">
                        <video poster="" id="so101-baseline-top" controls muted loop playsinline width="100%">
                            <source src="./static/videos/so101_baseline_fail_top.mp4" type="video/mp4">
                        </video>
                        <p class="is-size-6 mt-2 has-text-centered">Baseline (fail) - top view</p>
                    </div>
                    <div class="column is-6">
                        <video poster="" id="so101-vapt-top" controls muted loop playsinline width="100%">
                            <source src="./static/videos/so101_ours_success_top.mp4" type="video/mp4">
                        </video>
                        <p class="is-size-6 mt-2 has-text-centered">+ VAPT (success) - top view</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@article{choi2025d2e,
    title={D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied AI},
    author={Choi, Suhwan and Jung, Jaeyoon and Seong, Haebin and Kim, Minchan and Kim, Minyeong and Cho, Yongjun and Kim, Yoonshik and Park, Yubeen and Yu, Youngjae and Lee, Yunsung},
    journal={arXiv preprint arXiv:2510.05684},
    year={2025}
}</code></pre>
        </div>
    </section>
    <br>
    <center class="is-size-10">
        The website design was based on <a
            href="https://github.com/general-navigation-models/general-navigation-models.github.io"><span
                class="dnerf">general-navigation-models</span></a> adapted from <a href="https://nerfies.github.io"
            class="external-link"><span class="dnerf">Nerfies</span></a>.
    </center>
    <br>
</body>

</html>
